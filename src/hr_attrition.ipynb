{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ## **_Enterprise Data Science and Analytics - Enterprise Data Science Bootcamp_**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### **HR Attrition Project - EDSB25_26**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - Ana Rita Martins 20240821\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - Joana Coelho 20240801\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - Pedro Fernandes 20240823\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - Ricardo Silva 20240824"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Data Science and Analytics are reshaping how organizations solve problems across diverse industries. Through systematic data analysis and predictive modeling, evidence-based solutions can be developed, enabling more reliable decision-making and greater efficiency.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    In Human Resources, predictive analytics supports critical functions such as employee retention, workforce planning, and automated CV screening.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    This project focuses on developing predictive models to assess the likelihood of employee resignation. By analyzing factors ranging from demographics to job satisfaction, the models aim to provide interpretable insights that highlight key drivers of attrition. These insights will help HR leaders take proactive steps to reduce turnover and retain talent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ## 1. Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from summarytools import dfSummary\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ## 2. Importing Data and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/raw/HR_Attrition_Dataset.csv')\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) \n",
    "data.describe() \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include='object')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    From this initial inspection what immediately stands out is that we have 3 constant features: \"EmployeeCount\", \"StandardHours\", and \"Over18\". We can remove those straight away. Additionally, the employee number (ID) feature, does not seem to contain any relevant info, and  we'll drop it too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['EmployeeCount','Over18','StandardHours','EmployeeNumber'],inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = data.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "for col in cat_cols: \n",
    "    print(f\"Value counts for column '{col}':\")\n",
    "    print(data[col].value_counts())\n",
    "    print(\"\\n\") \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSummary(data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    From the summary above, we verified that the data set does't contain duplicates, and we also gathered information about the data's distribution and main statistics.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    What we can note is that, beasides our target, we have a couple of other binary features. Let's encode those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Attrition'] = data['Attrition'].map({'Yes': 1, 'No': 0})\n",
    "data['Gender'] = data['Gender'].map({'Male': 1, 'Female': 0})\n",
    "data['OverTime'] = data['OverTime'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "data.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Let's now have a look at how the distribution of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=data['Attrition'], hue=data['Attrition'], legend=False)\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)\n",
    "\n",
    "plt.title('Distribution of the Target Variable (Attrition)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We can observe that our target cariable is quite imbalanced. This will require extra attention in later steps, namely when splitting the dataset into train, validation and test sets, as well as during the modelling stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # **3. Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We'll start by plotting histograms to visually assess the distribution of the numeric features; this will allows us to spot any relevant patterns or trends in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(figsize=(20, 15))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The histograms reveal some important patterns in the dataset.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - Once again we can observe that the **target variable** is highly skewed toward staying in the company.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - Concerning demographics, **age** follows an approximately bell-shaped distribution, centered around 30-40; **Gender** is skewed with more males than females.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - Features that are related to **work characteristics** (YearsAtCompany, TotalWorkingYears, YearsInCurrentRole, Overtime) are right-skewed, indicating many relatively new employees and fewer with long careers; working overtime is not common.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - **Income**: Salaries and rates are right-skewed, with few very high earners.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - **Satisfaction-related** variables are discrete and somewhat skewed toward higher ratings, while PerformanceRating shows very little variation (nearly all at level 3), suggesting limited predictive value.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Overall, the data displays strong imbalance and skewness patterns that will require careful consideration during modeling, suggesting it could benefit from stratified splits, and algorithms robust to class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting  numerical columns (binaries excluded)\n",
    "binary_cols = ['Attrition', 'Gender', 'OverTime']\n",
    "num_cols = [col for col in data.select_dtypes(include=['int64', 'float64']).columns if col not in binary_cols]\n",
    "\n",
    "# Boxplots for each numerical feature\n",
    "n_cols = 5\n",
    "n_rows = -(-len(num_cols) // n_cols)  \n",
    "\n",
    "plt.figure(figsize=(20, 4*n_rows))\n",
    "\n",
    "for i, col in enumerate(num_cols, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    sns.boxplot(y=data[col])\n",
    "    plt.title(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The boxplots highlight the extent of skewness and make the outliers stand out clearly, which complements the histogram analysis above.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - Outliers are especially relevant in income and emplyment duration related-variables, which may need special handling. We'll decide how to handle them further down.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - For demographic/job characteristics (Age, DistanceFromHome, JobLevel, Education) featured the distributions are fairly compact with few outliers, aligning with the unimodal/bell-like shapes seen in histograms.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - Ordinal satisfaction and variables show limited spread, consistent with their discrete scale, with some level of skew toward higher values. Their limited range may reduce their explanatory power.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - PerformanceRating shows very little variation (nearly all values at level 3) confirming its limited usefulness as a predictive feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Subsequent steps may differ based on the category of each feature. Therefore, we’ll create lists that group feature names by their respective types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly define groups that cannot be inferred reliably\n",
    "feature_groups = {\n",
    "    \"binary\": ['Gender', 'OverTime'],\n",
    "    \"ordinal\": [\n",
    "        'Education','EnvironmentSatisfaction','JobInvolvement',\n",
    "        'JobLevel','JobSatisfaction','PerformanceRating',\n",
    "        'RelationshipSatisfaction','StockOptionLevel','WorkLifeBalance'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Infer remaining types\n",
    "all_features = data.columns.drop('Attrition')\n",
    "\n",
    "# Categorical = object dtype except those explicitly listed\n",
    "explicit_non_continuous = feature_groups[\"binary\"] + feature_groups[\"ordinal\"]\n",
    "categorical = (\n",
    "    data.select_dtypes(include='object')\n",
    "        .columns.difference(explicit_non_continuous)\n",
    "        .tolist()\n",
    ")\n",
    "\n",
    "# Continuous = numeric except explicit lists\n",
    "continuous = (\n",
    "    all_features\n",
    "        .difference(categorical + explicit_non_continuous)\n",
    "        .tolist()\n",
    ")\n",
    "\n",
    "feature_groups[\"categorical\"] = categorical\n",
    "feature_groups[\"continuous\"] = continuous\n",
    "feature_groups['non-continuous'] = feature_groups['binary'] + feature_groups['ordinal'] + categorical\n",
    "\n",
    "feature_groups\n",
    "#\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Let's now look at the distribution of our non-continuous features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in feature_groups['non-continuous']:\n",
    "\n",
    "    ax = sns.countplot(y=data[feature],order=data[feature].value_counts(ascending=False).index)\n",
    "    ax.set_xlabel('Number of Employees')\n",
    "\n",
    "    # Get data label values and concatenate them\n",
    "    abs_values = data[feature].value_counts(ascending=False).values\n",
    "    rel_values = data[feature].value_counts(ascending=False, normalize=True).values * 100\n",
    "    data_labels = [f'{label[0]} ({label[1]:.1f}%)' for label in zip(abs_values, rel_values)]\n",
    "\n",
    "    ax.bar_label(container=ax.containers[0], labels=data_labels)\n",
    "    ax.margins(x=0.25)\n",
    "    \n",
    " \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    From the variables that, a priori, we'd think could be related with attrition we find that:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     - roughly 30% of employees work overtime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     - roughly 40% have low to medium levels of satisfaction with the work environment\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     - roughly 30% report low to medium levels of job involvement\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     - nearly 40% report low to medium job satisfaction\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     - another nearly 40% have low to medium levels of satisfaction with relationships at work\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     - and about 5% report bad work-life balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    To better understand what might be contributing to employees’ decisions to quit, we'll next plot the non-continuous features against the target variable. We’ll also measure the attrition rate within each category. This will show us whether some groups are more prone to leaving than others, irrespective of their overall frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in feature_groups['non-continuous']:\n",
    "\n",
    "    # Get within category proportions\n",
    "    proportions = data.groupby(feature)['Attrition'].value_counts(normalize=True)\n",
    "\n",
    "    # Plot\n",
    "    ax = sns.countplot(y=data[feature], hue=data['Attrition'], order=data[feature].value_counts().sort_index().index)\n",
    "    ax.set_xlabel('Number of Employees')\n",
    "\n",
    "    # Insert proportions as data labels\n",
    "    for i, container in enumerate(ax.containers):\n",
    "        labels = [f'{proportions.loc[d,i]:.1%}' for d in sorted(data[feature].unique())]\n",
    "        ax.bar_label(container, labels)\n",
    "\n",
    "    ax.margins(x=0.15)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    From the plots above we find the following trends:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Department-level & Job roles:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - Sales and Human Resources show a higher proportion of employees quitting compared to R&D.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - Within job roles, HR professionals tend to leave more often, but so do Lab Technicians, even though they are part of the R&D department.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - Sales Representatives have the highest attrition rate across all job roles, whereas higher-level roles—such as managers and directors—show very low attrition.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Personal characteristics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - Single employees appear more likely to quit.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Work conditions and workload\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - Employees who work overtime, travel frequently, or have poor work–life balance are more likely to leave.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - Low satisfaction with the work environment, job involvement, overall job satisfaction, and relationships at work is also strongly associated with higher attrition.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Job level and hierarchy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - Employees in lower hierarchical levels tend to leave more often. However, attrition proportions do not strictly follow the hierarchical ranking order.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Stock ownership\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - Employees with no stock options (stock option level 0) are more prone to quitting. This is not surprising, as offering stock is a common strategy to increase engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Let's now run an equivalent analysis with our continuous features.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   We'll plot both their probability density function and violin plots and assess how their distribution relates to the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Attrition is binary for plotting aesthetics\n",
    "df_plot = data.copy()\n",
    "df_plot[\"Attrition\"] = df_plot[\"Attrition\"].astype(str)\n",
    "\n",
    "#attrition_num = df_plot[\"Attrition\"]\n",
    "\n",
    "continuous_vars = feature_groups[\"continuous\"]\n",
    "\n",
    "def plot_kde_violin(df, col):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # KDE plot\n",
    "    sns.kdeplot(\n",
    "        data=df, x=col, hue=\"Attrition\",\n",
    "        common_norm=False, fill=True, alpha=0.4, ax=axes[0]\n",
    "    )\n",
    "    axes[0].set_title(f\"KDE of {col} by Attrition\")\n",
    "    axes[0].set_xlabel(col)\n",
    "    axes[0].set_ylabel(\"Density\")\n",
    "    \n",
    "    # Violin plot\n",
    "    sns.violinplot(\n",
    "        data=df, hue=\"Attrition\", y=col,\n",
    "        inner=\"box\", ax=axes[1]\n",
    "    )\n",
    "    axes[1].set_title(f\"Violin Plot of {col} by Attrition\")\n",
    "    axes[1].set_xlabel(\"Attrition\")\n",
    "    axes[1].set_ylabel(col)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate combined plots for all continuous variables\n",
    "for col in continuous_vars:\n",
    "    plot_kde_violin(df_plot, col)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Some features show noticeable differences in their distributions depending on whether the employee quit or stayed.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Age and career stage\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - Employees who quit tend to be younger.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - This aligns with lower values observed in Total Working Years, Years at Company, Years in Current Role, and Years with Current Manager.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Early-career employees may be more inclined to change jobs or roles, contributing to these lower tenure metrics.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Compensation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - Monthly income appears influential: employees with lower income are more likely to leave, which is expected. The same applies to daily rate.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Distance from home\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - The larger the distance from home to work, the more likely the employees are to leave.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Other features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - The remaining continuous features either show similar distributions across attrition groups or differences too small to be clearly meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   We’ll now take look at the correlations among the features, including the target variable. This will help us identify potential collinearity, as well as highlight which features are associated with attrition. Since several features are not strictly numeric or continuous, we’ll use Spearman’s correlation, which measures monotonic relationships by correlating feature ranks rather than their raw values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   We'll exclude strictly nominal categorical variables (like Gender, Department, JobRole) because Spearman is rank-based, not meant for unordered categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting valid variables for Spearman\n",
    "\n",
    "df_corr = data.copy()\n",
    "\n",
    "ordinal_features = feature_groups[\"ordinal\"]\n",
    "continuous_features = feature_groups[\"continuous\"]\n",
    "\n",
    "spearman_vars = continuous_features + ordinal_features + [\"Attrition\"]\n",
    "df_spearman = df_corr[spearman_vars]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Spearman correlation matrix\n",
    "\n",
    "spearman_matrix = df_spearman.corr(method=\"spearman\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting sorted correlations with Attrition\n",
    "\n",
    "attrition_corr = spearman_matrix[\"Attrition\"].drop(\"Attrition\")\n",
    "attrition_corr_sorted = attrition_corr.sort_values(ascending=False)\n",
    "\n",
    "print(attrition_corr_sorted)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Spearman correlation matrix\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "mask = np.triu(np.ones_like(spearman_matrix, dtype=bool))\n",
    "\n",
    "sns.heatmap(spearman_matrix, mask=mask, cmap=\"coolwarm\", center=0, annot = True, fmt=\".2f\", square=True, cbar_kws={\"shrink\": .8})\n",
    "plt.title(\"Spearman Correlation Matrix\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   From the analyses and visualization above we observe that:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   - YearsAtCompany, YearsInCurrentRole, YearsWithCurrManager, TotalWorkingYears, JobLevel, MonthlyIncome, StockOptionLevel and Age are the strongest monotonic predictors of Attrition.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   These are indicators that relate to tenure, seniority, and stability and they're in agreement with HR domain knowledge: attrition is highest among newer, younger, lower-level employees.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   - JobSatisfaction, JobInvolvement, EnvironmentSatisfaction Tshow mild but potentially meaningful associations.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   Employees with lower satisfaction or lower involvement show slightly higher attrition.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = attrition_corr_sorted.abs().sort_values(ascending=False).head(12).index\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "mask = np.triu(np.ones_like(spearman_matrix.loc[top_features, top_features], dtype=bool))\n",
    "sns.heatmap(spearman_matrix.loc[top_features, top_features], mask=mask,\n",
    "            cmap=\"coolwarm\", center=0, annot=True, fmt=\".2f\")\n",
    "plt.title(\"Top Spearman Correlated Variables\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  The heatmap shows that several of the variables most strongly correlated with attrition are also highly collinear with each other. In particular, the following groups demonstrate very strong monotonic relationships (ρ > 0.70):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  - JobLevel — MonthlyIncome (ρ ≈ 0.92)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  - YearsInCurrentRole — YearsWithCurrManager (ρ ≈ 0.85)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  - TotalWorkingYears — MonthlyIncome (ρ ≈ 0.71)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  These features are all measures of: Tenure, Seniority, Career progression, Employee stability, which explains why they are tightly correlated with each other and with lower attrition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  While colinearity doesn't harm tree-based models, it does affect linear models like linear regression. Besides, it It also leads to unnecessary redundancy in the feature set. Keeping all of them increases the demand for computational powerr and increases the risk of overfitting. By the end of our feature selection process, we should aim to keep at most 2 or 3 representative variables of this set. And for regression models, we'll explicitly remove correlated pairs.\n",
    "\n",
    "\n",
    "\n",
    "  Another way to circumvent colinearity is to combine several colinear raw variables into a single engineered feature. Let's do that below.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TenureIndex (Average of three tenure-related variables)\n",
    "\n",
    "data[\"TenureIndex\"] = (\n",
    "    data[\"YearsAtCompany\"] +\n",
    "    data[\"YearsInCurrentRole\"] +\n",
    "    data[\"YearsWithCurrManager\"]\n",
    ") / 3\n",
    "\n",
    "\n",
    "# PromotionGap (Time in company since last promotion: a proxy for stagnation)\n",
    "\n",
    "data[\"PromotionGap\"] = data[\"YearsAtCompany\"] - data[\"YearsSinceLastPromotion\"]\n",
    "\n",
    "# avoid negative values if any weird records exist\n",
    "data[\"PromotionGap\"] = data[\"PromotionGap\"].clip(lower=0)\n",
    "\n",
    "# EngagementIndex (Composite of satisfaction / involvement metrics)\n",
    "\n",
    "engagement_cols = [\n",
    "    \"JobInvolvement\",\n",
    "    \"JobSatisfaction\",\n",
    "    \"EnvironmentSatisfaction\",\n",
    "    \"RelationshipSatisfaction\"\n",
    "]\n",
    "\n",
    "data[\"EngagementIndex\"] = data[engagement_cols].mean(axis=1)\n",
    "\n",
    "# IncomeVsRoleMedian (Relative pay vs median in same job role)\n",
    "\n",
    "# Compute median income per JobRole\n",
    "role_median_income = data.groupby(\"JobRole\")[\"MonthlyIncome\"].transform(\"median\")\n",
    "\n",
    "data[\"IncomeVsRoleMedian\"] = data[\"MonthlyIncome\"] / role_median_income\n",
    "\n",
    "\n",
    "data['Income_Rate_Ratio'] = data['MonthlyIncome'] / data['MonthlyRate']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered = [\"TenureIndex\", \"PromotionGap\", \"EngagementIndex\", \"IncomeVsRoleMedian\", \"Income_Rate_Ratio\"]\n",
    "\n",
    "spearman_corrs = (\n",
    "    data[engineered + [\"Attrition\"]]\n",
    "    .corr(method=\"spearman\")[\"Attrition\"]\n",
    "    .drop(\"Attrition\")\n",
    ")\n",
    "\n",
    "print(spearman_corrs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Preprocessing Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Before any encoding and feature selection steps we'll start by defining X and y, and defining the train–test split. Doing this at this satge is critical to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = data.drop('Attrition', axis=1).copy()\n",
    "y = data['Attrition'].copy()\n",
    "\n",
    "# Train–test split (20% test, stratified by target)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y,      # keep same attrition proportion in train/test; very important given class imbalance\n",
    "    shuffle=True     \n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Rebuilding feature groups on X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Categorical features inferred from dtype 'object'\n",
    "categorical_features = list(\n",
    "    X_train.select_dtypes(include='object').columns.drop(['BusinessTravel'])\n",
    ")\n",
    "\n",
    "# 2. Binary features (defined them manually above)\n",
    "binary_features = ['Gender', 'OverTime']\n",
    "\n",
    "# 3. Ordinal features (predefined list above)\n",
    "ordinal_features = [\n",
    "    'BusinessTravel','Education','EnvironmentSatisfaction','JobInvolvement',\n",
    "    'JobLevel','JobSatisfaction','PerformanceRating',\n",
    "    'RelationshipSatisfaction','StockOptionLevel','WorkLifeBalance'\n",
    "]\n",
    "\n",
    "# 4. Non-continuous = categorical + binary + ordinal\n",
    "non_continuous_features = categorical_features + binary_features + ordinal_features\n",
    "\n",
    "# 5. Continuous = everything else except the target (including engineered features)\n",
    "continuous_features = list(\n",
    "    X_train.columns.difference(non_continuous_features)\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Categorical nominal:\", categorical_features)\n",
    "print(\"Binary:\", binary_features)\n",
    "print(\"Ordinal:\", ordinal_features)\n",
    "print(\"Continuous (incl. engineered):\", continuous_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Defining the preprocessing (encoders + passthrough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal encoder for ordinal features\n",
    "\n",
    "ordinal_transformer = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# One-hot encoder for nominal + binary\n",
    "\n",
    "onehot_transformer = OneHotEncoder(\n",
    "    drop=None,                 # or 'first' if you want k-1 dummies\n",
    "    handle_unknown='ignore',   # ignore categories not seen during fit\n",
    "    sparse_output=False        # get a dense array, easier to wrap in DataFrame\n",
    ")\n",
    "\n",
    "# ColumnTransformer ties it together\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ord',   ordinal_transformer, ordinal_features),\n",
    "        ('nom',   onehot_transformer, categorical_features + binary_features),\n",
    "        ('num',   'passthrough',      continuous_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  When preprocess.fit(X_train) is called, it learns: category mappings for ordinal features; dummy columns for nominal + binary.\n",
    "\n",
    "\n",
    "\n",
    "  Then preprocess.transform(...) will apply this same mapping to train & test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Combining preprocessing + scaling into a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_preprocess = Pipeline([\n",
    "    ('preprocess', preprocess),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Fitting preprocessing only on training data and transform both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on training data only (no leakage)\n",
    "pipeline_preprocess.fit(X_train)\n",
    "\n",
    "# Transform train and test with the same fitted pipeline\n",
    "X_train_processed = pipeline_preprocess.transform(X_train)\n",
    "X_test_processed  = pipeline_preprocess.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train_processed shape:\", X_train_processed.shape)\n",
    "print(\"X_test_processed shape:\",  X_test_processed.shape)\n",
    "\n",
    "#print(\"Number of feature names:\", len(feature_names))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Grab the ColumnTransformer from the pipeline\n",
    "ct = pipeline_preprocess.named_steps['preprocess']\n",
    "\n",
    "# 2. Ask it for the output feature names\n",
    "feature_names = ct.get_feature_names_out()\n",
    "\n",
    "# 3. Now rebuild the DataFrames\n",
    "X_train_df = pd.DataFrame(X_train_processed, columns=feature_names, index=X_train.index)\n",
    "X_test_df  = pd.DataFrame(X_test_processed,  columns=feature_names, index=X_test.index)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Chi-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def chi_square_for_feature(X_col, y):\n",
    "    \"\"\"Return chi2 and p-value for one categorical feature vs target.\"\"\"\n",
    "    table_observed = pd.crosstab(y, X_col)\n",
    "    chi2, pvalue, dof, expected = stats.chi2_contingency(table_observed.values)\n",
    "    return chi2, pvalue\n",
    "\n",
    "\n",
    "def chi_square_for_features(X_train, y_train, alpha=0.05):\n",
    "    \"\"\"Run chi-square for each column in X_train and return a summary DataFrame.\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for var in X_train.columns:\n",
    "        chi2, pvalue = chi_square_for_feature(X_train[var], y_train)\n",
    "        results.append({\n",
    "            \"feature\": var,\n",
    "            \"chi2\": chi2,\n",
    "            \"p_value\": pvalue,\n",
    "            \"significant\": pvalue < alpha\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    # Sort by p-value (smallest p-value = strongest evidence of association)\n",
    "    results_df = results_df.sort_values(\"p_value\")\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_results = chi_square_for_features(\n",
    "    X_train[non_continuous_features],\n",
    "    y_train,\n",
    "    alpha=0.05\n",
    ")\n",
    "\n",
    "chi2_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_mutual_information_from_ct(ct, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Compute mutual information between each encoded feature and the target,\n",
    "    using a fitted ColumnTransformer 'ct' (without scaling).\n",
    "    Returns a sorted DataFrame with MI scores.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Transform X_train with the fitted ColumnTransformer (no scaling)\n",
    "    X_train_enc = ct.transform(X_train)\n",
    "    feature_names = ct.get_feature_names_out()\n",
    "\n",
    "    X_train_enc_df = pd.DataFrame(\n",
    "        X_train_enc,\n",
    "        columns=feature_names,\n",
    "        index=X_train.index\n",
    "    )\n",
    "\n",
    "    # 2. Build a mask of which features are discrete\n",
    "    col_series = X_train_enc_df.columns.to_series()\n",
    "    discrete_mask = col_series.str.startswith(('ord__', 'nom__'))\n",
    "\n",
    "    # 3. Compute mutual information\n",
    "    mi_scores = mutual_info_classif(\n",
    "        X_train_enc_df,\n",
    "        y_train,\n",
    "        discrete_features=discrete_mask.values,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # 4. Build results DataFrame\n",
    "    mi_df = pd.DataFrame({\n",
    "        'Feature': X_train_enc_df.columns,\n",
    "        'MI': mi_scores,\n",
    "        'Discrete': discrete_mask.values\n",
    "    })\n",
    "\n",
    "    mi_df.sort_values('MI', ascending=False, inplace=True)\n",
    "    mi_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return mi_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the fitted ColumnTransformer from the pipeline\n",
    "ct = pipeline_preprocess.named_steps['preprocess']\n",
    "\n",
    "mi_results = compute_mutual_information_from_ct(ct, X_train, y_train)\n",
    "display(mi_results.head(20))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## L1 Logistic Regression (LASSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_with_l1_logistic(X_train_df, y_train, C=1.0):\n",
    "    \"\"\"\n",
    "    Run L1-penalized Logistic Regression to select features.\n",
    "    Returns a DataFrame with coefficients and selection mask.\n",
    "    \"\"\"\n",
    "    # L1 logistic regression with class balancing (important for attrition)\n",
    "    l1_model = LogisticRegression(\n",
    "        penalty='l1',\n",
    "        solver='liblinear',\n",
    "        class_weight='balanced',\n",
    "        C=C,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    selector = SelectFromModel(l1_model, prefit=False)\n",
    "    selector.fit(X_train_df, y_train)\n",
    "\n",
    "    # Selected mask\n",
    "    mask = selector.get_support()\n",
    "\n",
    "    # Coefficients\n",
    "    coefs = selector.estimator_.coef_[0]\n",
    "\n",
    "    # Build results table\n",
    "    results = pd.DataFrame({\n",
    "        \"Feature\": X_train_df.columns,\n",
    "        \"Coefficient\": coefs,\n",
    "        \"Selected\": mask\n",
    "    })\n",
    "\n",
    "    # Absolute magnitude for sorting\n",
    "    results[\"AbsCoef\"] = results[\"Coefficient\"].abs()\n",
    "    results = results.sort_values(\"AbsCoef\", ascending=False)\n",
    "\n",
    "    return results, mask\n",
    "\n",
    "l1_results, l1_mask = select_with_l1_logistic(X_train_df, y_train)\n",
    "display(l1_results.head(20))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Features with Selected = True are part of the sparse LASSO-selected subset. Larger coefficients (in magnitude) reflect stronger linear effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Random Forest captures: nonlinearities, interactions, categorical effects, monotonic or non-monotonic patterns. Works very well alongside LASSO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_with_random_forest(X_train_df, y_train, n_estimators=500):\n",
    "    \"\"\"\n",
    "    Train a Random Forest and return a DataFrame with feature importances.\n",
    "    \"\"\"\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        random_state=42,\n",
    "        class_weight='balanced',\n",
    "        max_depth=None,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    rf.fit(X_train_df, y_train)\n",
    "\n",
    "    importances = rf.feature_importances_\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        \"Feature\": X_train_df.columns,\n",
    "        \"Importance\": importances\n",
    "    }).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "    return results, rf\n",
    "\n",
    "rf_results, rf_model = select_with_random_forest(X_train_df, y_train)\n",
    "display(rf_results.head(20))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## XGBoost Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  XGBoost is often very strong at discovering: threshold effects, feature interactions, nonlinear jump patterns, sparse informative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_with_xgboost(X_train_df, y_train):\n",
    "    \"\"\"\n",
    "    Train XGBoost and return feature importances.\n",
    "    \"\"\"\n",
    "\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "\n",
    "    xgb.fit(X_train_df, y_train)\n",
    "\n",
    "    importances = xgb.feature_importances_\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        \"Feature\": X_train_df.columns,\n",
    "        \"Importance\": importances\n",
    "    }).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "    return results, xgb\n",
    "\n",
    "xgb_results, xgb_model = select_with_xgboost(X_train_df, y_train)\n",
    "display(xgb_results.head(20))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Table Combining Feature Selection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting from all encoded features\n",
    "\n",
    "# Base table: one row per encoded feature\n",
    "unified_fs = pd.DataFrame({\n",
    "    \"Feature\": X_train_df.columns\n",
    "})\n",
    "\n",
    "\n",
    "# Merging MI results\n",
    "\n",
    "# Keep only needed columns from MI\n",
    "mi_short = mi_results[[\"Feature\", \"MI\"]]\n",
    "\n",
    "unified_fs = unified_fs.merge(\n",
    "    mi_short,\n",
    "    on=\"Feature\",\n",
    "    how=\"left\")\n",
    "\n",
    "#Merging L1 Logistic Regression results\n",
    "\n",
    "l1_short = l1_results[[\"Feature\", \"Coefficient\", \"Selected\"]]\n",
    "\n",
    "unified_fs = unified_fs.merge(\n",
    "    l1_short,\n",
    "    on=\"Feature\",\n",
    "    how=\"left\")\n",
    "\n",
    "# Merging Random Forest results\n",
    "\n",
    "rf_short = rf_results.rename(columns={\"Importance\": \"RF_importance\"})[\n",
    "    [\"Feature\", \"RF_importance\"]\n",
    "]\n",
    "\n",
    "unified_fs = unified_fs.merge(\n",
    "    rf_short,\n",
    "    on=\"Feature\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Merging XGBoost results\n",
    "\n",
    "xgb_short = xgb_results.rename(columns={\"Importance\": \"XGB_importance\"})[\n",
    "    [\"Feature\", \"XGB_importance\"]\n",
    "]\n",
    "\n",
    "unified_fs = unified_fs.merge(\n",
    "    xgb_short,\n",
    "    on=\"Feature\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping encoded features back to their raw feature name\n",
    "\n",
    "def get_raw_feature_name(encoded_feature):\n",
    "    \"\"\"\n",
    "    Map an encoded feature name (ord__/nom__/num__) back to the original column name.\n",
    "\n",
    "    Examples:\n",
    "      'ord__JobLevel'                      -> 'JobLevel'\n",
    "      'nom__BusinessTravel_Travel_Rarely'  -> 'BusinessTravel'\n",
    "      'nom__MaritalStatus_Single'          -> 'MaritalStatus'\n",
    "      'num__Age'                           -> 'Age'\n",
    "    \"\"\"\n",
    "    if encoded_feature.startswith(\"num__\") or encoded_feature.startswith(\"ord__\"):\n",
    "        # pattern: 'num__Age' or 'ord__JobLevel'\n",
    "        return encoded_feature.split(\"__\", 1)[1]\n",
    "\n",
    "    if encoded_feature.startswith(\"nom__\"):\n",
    "        # pattern: 'nom__Column_Category_With_Underscores'\n",
    "        tmp = encoded_feature.split(\"__\", 1)[1]  # 'Column_Category...'\n",
    "        raw_col = tmp.split(\"_\", 1)[0]           # take part before first '_'\n",
    "        return raw_col\n",
    "\n",
    "    # For any unexpected feature, return None\n",
    "    return None\n",
    "\n",
    "unified_fs[\"raw_feature\"] = unified_fs[\"Feature\"].apply(get_raw_feature_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Chi-square results by raw feature\n",
    "\n",
    "chi2_short = chi2_results.rename(columns={\n",
    "    \"feature\": \"raw_feature\",\n",
    "    \"chi2\": \"chi2_stat\",\n",
    "    \"p_value\": \"chi2_pvalue\",\n",
    "    \"significant\": \"chi2_significant\"\n",
    "})[[\"raw_feature\", \"chi2_stat\", \"chi2_pvalue\", \"chi2_significant\"]]\n",
    "\n",
    "unified_fs = unified_fs.merge(\n",
    "    chi2_short,\n",
    "    on=\"raw_feature\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flagging whether feature is discrete (ordinal or one-hot)\n",
    "\n",
    "unified_fs[\"is_discrete\"] = unified_fs[\"Feature\"].str.startswith((\"ord__\", \"nom__\"))\n",
    "\n",
    "# Possible sorting: by Random Forest importance (descending)\n",
    "unified_fs_sorted = unified_fs.sort_values(\n",
    "    by=[\"RF_importance\", \"XGB_importance\", \"MI\"],\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "unified_fs_sorted.head(30)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Finding which variables are consistently selected by the different feature selection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = unified_fs.copy()  # keeping the original safe\n",
    "\n",
    "# Fill NaNs with 0 where it makes sense \n",
    "df[\"MI\"] = df[\"MI\"].fillna(0)\n",
    "df[\"RF_importance\"] = df[\"RF_importance\"].fillna(0)\n",
    "df[\"XGB_importance\"] = df[\"XGB_importance\"].fillna(0)\n",
    "\n",
    "# chi2_significant may be NaN for numeric features; treat those as False\n",
    "df[\"chi2_significant\"] = df[\"chi2_significant\"].fillna(False)\n",
    "\n",
    "# L1 Selected may be NaN for some features; treat as False\n",
    "df[\"Selected\"] = df[\"Selected\"].fillna(False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Establishing dynamic thresholds (quantile-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to get a quantile threshold, but avoid NaNs / all-zeros issues\n",
    "def safe_quantile(series, q, default=0.0):\n",
    "    vals = series.dropna()\n",
    "    if (vals > 0).sum() == 0:\n",
    "        return default\n",
    "    return vals.quantile(q)\n",
    "\n",
    "# Example: top 30% for MI, RF, XGB\n",
    "mi_thresh  = safe_quantile(df[\"MI\"],             0.70, default=0.0)\n",
    "rf_thresh  = safe_quantile(df[\"RF_importance\"],  0.70, default=0.0)\n",
    "xgb_thresh = safe_quantile(df[\"XGB_importance\"], 0.70, default=0.0)\n",
    "\n",
    "print(\"MI threshold:\", mi_thresh)\n",
    "print(\"RF threshold:\", rf_thresh)\n",
    "print(\"XGB threshold:\", xgb_thresh)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Defining binary flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Chi-square (categoricals only) – already a boolean\n",
    "df[\"chi2_good\"] = df[\"chi2_significant\"].astype(bool)\n",
    "\n",
    "# 2) Mutual Information – above quantile threshold\n",
    "df[\"mi_good\"] = (df[\"MI\"] >= mi_thresh)\n",
    "\n",
    "# 3) L1 Logistic Regression – already boolean\n",
    "df[\"l1_good\"] = df[\"Selected\"].astype(bool)\n",
    "\n",
    "# 4) Random Forest – above quantile threshold\n",
    "df[\"rf_good\"] = (df[\"RF_importance\"] >= rf_thresh)\n",
    "\n",
    "# 5) XGBoost – above quantile threshold\n",
    "df[\"xgb_good\"] = (df[\"XGB_importance\"] >= xgb_thresh)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Building the consensus score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_flags = [\"chi2_good\", \"mi_good\", \"l1_good\", \"rf_good\", \"xgb_good\"]\n",
    "\n",
    "# Converting to int and sum\n",
    "df[\"consensus_score\"] = df[method_flags].astype(int).sum(axis=1)\n",
    "\n",
    "# Checking distribution\n",
    "print(df[\"consensus_score\"].value_counts().sort_index())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Defining Feature Set A (strict) and Feature Set B (moderate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strict: features that get at least 3 \"votes\"\n",
    "strict_mask = df[\"consensus_score\"] >= 3\n",
    "\n",
    "# Moderate: at least 2 votes\n",
    "moderate_mask = df[\"consensus_score\"] >= 2\n",
    "\n",
    "# Feature names (encoded, ready for modelling)\n",
    "features_strict   = df.loc[strict_mask,   \"Feature\"].tolist()\n",
    "features_moderate = df.loc[moderate_mask, \"Feature\"].tolist()\n",
    "\n",
    "print(\"Number of features in strict set:\", len(features_strict))\n",
    "print(\"Number of features in moderate set:\", len(features_moderate))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consensus_view = df[[\n",
    "    \"Feature\",\n",
    "    \"raw_feature\",\n",
    "    \"MI\",\n",
    "    \"Coefficient\",\n",
    "    \"RF_importance\",\n",
    "    \"XGB_importance\",\n",
    "    \"chi2_stat\",\n",
    "    \"chi2_pvalue\",\n",
    "    \"chi2_good\",\n",
    "    \"mi_good\",\n",
    "    \"l1_good\",\n",
    "    \"rf_good\",\n",
    "    \"xgb_good\",\n",
    "    \"consensus_score\"\n",
    "]].sort_values(\"consensus_score\", ascending=False)\n",
    "\n",
    "df_consensus_view.head(30)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strict set of features\n",
    "\n",
    "for i, f in enumerate(features_strict, 1):\n",
    "    print(f\"{i}. {f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This strict set leans heavily toward a few thematic clusters:\n",
    "\n",
    "\n",
    "\n",
    " - Career progression & seniority (Age, TotalWorkingYears, YearsAtCompany, YearsWithCurrManager, JobLevel)\n",
    "\n",
    " - Income & compensation (MonthlyIncome, Income_Rate_Ratio, StockOptionLevel)\n",
    "\n",
    " - Job role (4–5 JobRole dummies)\n",
    "\n",
    " - Marital status (Single / Divorced)\n",
    "\n",
    " - OverTime\n",
    "\n",
    " - EngagementIndex\n",
    "\n",
    " - BusinessTravel\n",
    "\n",
    "\n",
    "\n",
    " These are well known drivers of attrition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modearate set of features\n",
    "\n",
    "for i, f in enumerate(features_moderate, 1):\n",
    "    print(f\"{i}. {f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The moderate feature set as expected is more comprehensive and could be particularly useful for tree-based models. Of note, all engineered features are included in this set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The following modelling function:\n",
    "\n",
    "\n",
    "\n",
    " - accepts a feature list (strict or moderate)\n",
    "\n",
    " - uses the pipeline_preprocess for encoding & scaling\n",
    "\n",
    " - runs cross-validation on the training set\n",
    "\n",
    " - evaluates several metrics\n",
    "\n",
    " - trains the final model on the full training set\n",
    "\n",
    " - evaluates it on the held-out test set\n",
    "\n",
    "\n",
    "\n",
    " This will be the function we'll reuse for comparing different models as well as strict feature set vs moderate feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_preprocessed(\n",
    "    model,\n",
    "    feature_list,\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    pipeline_preprocess,\n",
    "    n_splits=5\n",
    "):\n",
    "\n",
    "    # ----- 1. Fit + transform preprocessing -----\n",
    "    pipeline_preprocess.fit(X_train)\n",
    "    X_train_prep = pipeline_preprocess.transform(X_train)\n",
    "    X_test_prep  = pipeline_preprocess.transform(X_test)\n",
    "\n",
    "    feature_names = pipeline_preprocess.get_feature_names_out()\n",
    "\n",
    "    # ----- 2. Select strict / moderate features -----\n",
    "    name_to_idx = {name: i for i, name in enumerate(feature_names)}\n",
    "    idx = [name_to_idx[f] for f in feature_list]\n",
    "\n",
    "    X_train_sel = X_train_prep[:, idx]\n",
    "    X_test_sel  = X_test_prep[:, idx]\n",
    "\n",
    "    # ----- 3. CV -----\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    cv_acc, cv_prec, cv_rec, cv_f1 = [], [], [], []\n",
    "\n",
    "    for train_i, val_i in skf.split(X_train_sel, y_train):\n",
    "        X_tr = X_train_sel[train_i];   y_tr = y_train.iloc[train_i]\n",
    "        X_val = X_train_sel[val_i];    y_val = y_train.iloc[val_i]\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "        preds = model.predict(X_val)\n",
    "\n",
    "        cv_acc.append(accuracy_score(y_val, preds))\n",
    "        cv_prec.append(precision_score(y_val, preds))\n",
    "        cv_rec.append(recall_score(y_val, preds))\n",
    "        cv_f1.append(f1_score(y_val, preds))\n",
    "\n",
    "    # ----- 4. Final fit -----\n",
    "    model.fit(X_train_sel, y_train)\n",
    "\n",
    "    # ----- 5. Test set -----\n",
    "    preds = model.predict(X_test_sel)\n",
    "\n",
    "    results = {\n",
    "        \"cv_accuracy\":   np.mean(cv_acc),\n",
    "        \"cv_precision\":  np.mean(cv_prec),\n",
    "        \"cv_recall\":     np.mean(cv_rec),\n",
    "        \"cv_f1\":         np.mean(cv_f1),\n",
    "        \"test_accuracy\":  accuracy_score(y_test, preds),\n",
    "        \"test_precision\": precision_score(y_test, preds),\n",
    "        \"test_recall\":    recall_score(y_test, preds),\n",
    "        \"test_f1\":        f1_score(y_test, preds)\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model factory functions: each call returns a FRESH instance ---\n",
    "\n",
    "def make_lr():\n",
    "    return LogisticRegression(\n",
    "        class_weight='balanced',\n",
    "        max_iter=500,\n",
    "        solver='lbfgs',\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "def make_rf():\n",
    "    return RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "def make_xgb():\n",
    "    # handle imbalance with scale_pos_weight\n",
    "    pos = y_train.sum()\n",
    "    neg = len(y_train) - pos\n",
    "    spw = neg / pos\n",
    "    \n",
    "    return XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        scale_pos_weight=spw,\n",
    "        random_state=42,\n",
    "        eval_metric='logloss',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "def make_mlp():\n",
    "    return MLPClassifier(\n",
    "        hidden_layer_sizes=(32,),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        alpha=1e-4,\n",
    "        learning_rate_init=1e-3,\n",
    "        max_iter=300,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "def make_svc():\n",
    "    return SVC(\n",
    "        kernel='rbf',\n",
    "        C=1.0,\n",
    "        gamma='scale',\n",
    "        probability=True,         # in case you later want predict_proba\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "def make_lgbm():\n",
    "    return LGBMClassifier(\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=-1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "\n",
    "def make_cat():\n",
    "    return CatBoostClassifier(\n",
    "        iterations=400,\n",
    "        depth=4,\n",
    "        learning_rate=0.1,\n",
    "        loss_function='Logloss',\n",
    "        eval_metric='F1',\n",
    "        auto_class_weights='Balanced',\n",
    "        random_state=42,\n",
    "        verbose=False\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_factories = {\n",
    "    \"LR\":   make_lr,\n",
    "    \"RF\":   make_rf,\n",
    "    \"XGB\":  make_xgb,\n",
    "    \"MLP\":  make_mlp,\n",
    "    \"SVC\":  make_svc,\n",
    "    \"LGBM\": make_lgbm,\n",
    "    \"CAT\":  make_cat\n",
    "}\n",
    "\n",
    "feature_sets = {\n",
    "    \"strict\":   features_strict,\n",
    "    \"moderate\": features_moderate\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = []\n",
    "\n",
    "for model_name, factory in model_factories.items():\n",
    "    for fs_name, fs_list in feature_sets.items():\n",
    "        print(f\"Running {model_name} with {fs_name} features...\")\n",
    "        \n",
    "        model = factory()  # FRESH instance each time\n",
    "        \n",
    "        res = evaluate_model_preprocessed(\n",
    "            model=model,\n",
    "            feature_list=fs_list,\n",
    "            X_train=X_train, y_train=y_train,\n",
    "            X_test=X_test, y_test=y_test,\n",
    "            pipeline_preprocess=pipeline_preprocess\n",
    "        )\n",
    "        \n",
    "        # add identifiers\n",
    "        res[\"model\"] = model_name\n",
    "        res[\"feature_set\"] = fs_name\n",
    "        \n",
    "        baseline_results.append(res)\n",
    "\n",
    "# Convert to DataFrame for nice viewing\n",
    "results_df = pd.DataFrame(baseline_results)\n",
    "\n",
    "# Put columns in a convenient order\n",
    "cols_order = [\n",
    "    \"model\", \"feature_set\",\n",
    "    \"cv_accuracy\", \"cv_precision\", \"cv_recall\", \"cv_f1\",\n",
    "    \"test_accuracy\", \"test_precision\", \"test_recall\", \"test_f1\"\n",
    "]\n",
    "results_df = results_df[cols_order]\n",
    "\n",
    "results_df\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
